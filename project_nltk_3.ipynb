{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev = pd.read_csv(Path.cwd()/'data'/'DSL2122_january_dataset'/'development.csv')\n",
    "df_eval = pd.read_csv(Path.cwd()/'data'/'DSL2122_january_dataset'/'evaluation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74999, 5)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_dev.append(df_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['date'] = df['date'].\\\n",
    "#     astype('string')\\\n",
    "#     .str.split(' ')\\\n",
    "#     .apply(lambda x : ' '.join([x[i] for i in [1,2,3,5]]))\\\n",
    "#     .pipe(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords analysis: sklearn, nltk, stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\edo_c\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk import download as nltk_download\n",
    "\n",
    "nltk_download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk_stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "\n",
    "sklearn_stopwords = list(text.ENGLISH_STOP_WORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stop_words import get_stop_words\n",
    "\n",
    "stop_words_stopwords = get_stop_words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I should try to use both all stopwords, and sklearn and nltk stopwords singularly (and also no stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwords_list_gen(source_list = [sklearn_stopwords,nltk_stopwords], generate_neg = True):\n",
    "    stopwords_all_list = set()\n",
    "    for source in source_list:\n",
    "        stopwords_all_list = stopwords_all_list.union(set(source))\n",
    "        if generate_neg:\n",
    "            stopwords_all_list = stopwords_all_list.union(set([f'{i+\"_neg\"}' for i in source]))\n",
    "    return stopwords_all_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_token'] = df['text'].str.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removal of '@words'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_noAt'] = df['text_token'].apply(lambda x : [i for i in x if not(i.startswith('@'))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removal of '&amp' and '&quot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_noAmpQuot'] = df['text_noAt']\\\n",
    "    .apply(lambda x : [i for i in x if '&amp' not in i])\\\n",
    "    .apply(lambda x : [i for i in x if '&quot' not in i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removal of repeated letters (incomplete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'ulaaa'\n",
    "\n",
    "def remove_repeated_letters(word):\n",
    "    for letter in word:\n",
    "        print(letter)\n",
    "\n",
    "# nltk_stemmer.stem(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove puntuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string as py_string\n",
    "df['text_noPunct'] = df['text_noAmpQuot']\\\n",
    "    .apply(lambda x : [i.translate(str.maketrans('', '', py_string.punctuation)) for i in x])\\\n",
    "    .apply(lambda x : [i for i in x if i != ''])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.util import mark_negation\n",
    "\n",
    "df['text_neg'] = df['text_noPunct'].apply(lambda x : mark_negation(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removal of stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "considered_stopwords = stop_words_stopwords + [f'{word}_neg' for word in stop_words_stopwords]\n",
    "\n",
    "df['text_noStopwords'] = df['text_neg'].apply(lambda x : [i for i in x if i not in considered_stopwords])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming and lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer, WordNetLemmatizer\n",
    "\n",
    "# nltk_download('wordnet')\n",
    "# nltk_download('omw-1.4')\n",
    "\n",
    "# nltk_stemmer = PorterStemmer()\n",
    "# # nltk_stemmer = LancasterStemmer()\n",
    "# # nltk_stemmer = SnowballStemmer('english')\n",
    "# nltk_lemmatizer = WordNetLemmatizer()\n",
    "# # from nltk.corpus import wordnet\n",
    "\n",
    "# df['text_stemmed'] = df['text_noPunct'].apply(lambda x : [nltk_stemmer.stem(word) for word in x])\n",
    "# df['text_stemmed'] = df['text_noPunct'].apply(lambda x : [nltk_lemmatizer.lemmatize(word) for word in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User manual filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[\n",
    "    (~(df['user'] == 'lost_dog') &\n",
    "    ~(df['user'] == 'webwoke') &\n",
    "    ~(df['user'] == 'tweetpet') &\n",
    "    ~(df['user'].str.contains('tweeteradder')) &\n",
    "    ~(df['user'].str.contains('tweetfollow')) &\n",
    "    ~(df['user'] == 'divxdownloads')) |\n",
    "    df['sentiment'].isna()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74999, 12)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['sentiment'].isna()].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "df_final = df\n",
    "df_final['text_final'] = df_final['text_noPunct'].apply(lambda x : ' '.join(x))\n",
    "# df_final['text_final'] = df_final['text']\n",
    "\n",
    "# stopwords_to_use = [nltk_stemmer.stem(word) for word in stopwords_list_gen()]\n",
    "# stopwords_to_use = [nltk_stemmer.stem(word) for word in sklearn_stopwords]\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    # stop_words = stopwords_to_use,\n",
    "    # stop_words = 'english',\n",
    "    stop_words = None,\n",
    "    binary=True, \n",
    "    use_idf=True, \n",
    "    norm='l2',\n",
    "    smooth_idf=True\n",
    ")\n",
    "\n",
    "wpm = vectorizer.fit_transform(df_final['text_final'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing with truncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(297949, 2300)\n",
      "(222950, 2300)\n",
      "(222950,)\n",
      "(74999, 2300)\n"
     ]
    }
   ],
   "source": [
    "N = 2300\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=N, n_iter=10, random_state=42)\n",
    "\n",
    "wpm_svd = svd.fit_transform(wpm)\n",
    "\n",
    "print(wpm_svd.shape)\n",
    "\n",
    "features_df = pd.DataFrame(\n",
    "    data = wpm_svd,\n",
    "    index = df_final.index\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "mask_train_test = df_final['sentiment'].notna()\n",
    "\n",
    "X_train_valid = features_df.loc[mask_train_test,:].values\n",
    "y_train_valid = df_final.loc[mask_train_test,:]['sentiment'].values\n",
    "X_test = features_df.loc[~mask_train_test,:].values\n",
    "\n",
    "print(X_train_valid.shape)\n",
    "print(y_train_valid.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_valid, \n",
    "    y_train_valid, \n",
    "    shuffle=True, \n",
    "    # stratify=y_train_valid, \n",
    "    train_size=0.8, \n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing without truncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(222950, 500)\n",
      "(222950,)\n",
      "(74999, 500)\n"
     ]
    }
   ],
   "source": [
    "N = 500\n",
    "\n",
    "word_freq = pd.Series(\n",
    "    data = np.asarray(wpm.sum(axis=0)).squeeze(),\n",
    "    index = vectorizer.get_feature_names_out()\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "word_freq = word_freq[:N]\n",
    "\n",
    "word_ind = [w in word_freq.index for w in vectorizer.get_feature_names_out()]\n",
    "\n",
    "words_df = pd.DataFrame(\n",
    "    data = wpm[:,word_ind].toarray(),\n",
    "    columns = vectorizer.get_feature_names_out()[word_ind],\n",
    "    index = df_final.index\n",
    ").add_prefix('word_')\n",
    "\n",
    "# words_df\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "mask_train_test = df_final['sentiment'].notna()\n",
    "\n",
    "X_train_valid = words_df.loc[mask_train_test,:].values\n",
    "y_train_valid = df_final.loc[mask_train_test,:]['sentiment'].values\n",
    "X_test = words_df.loc[~mask_train_test,:].values\n",
    "\n",
    "print(X_train_valid.shape)\n",
    "print(y_train_valid.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_valid, \n",
    "    y_train_valid, \n",
    "    shuffle=True, \n",
    "    # stratify=y_train_valid, \n",
    "    train_size=0.8, \n",
    "    random_state=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7029172012424388\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.58      0.64     18800\n",
      "         1.0       0.73      0.81      0.77     25790\n",
      "\n",
      "    accuracy                           0.72     44590\n",
      "   macro avg       0.71      0.70      0.70     44590\n",
      "weighted avg       0.72      0.72      0.71     44590\n",
      "\n",
      "[[10996  7804]\n",
      " [ 4774 21016]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "\n",
    "rfc = RandomForestClassifier(\n",
    "    n_estimators = 150, \n",
    "    random_state = 42, \n",
    "    min_impurity_decrease = 0.0,\n",
    "    n_jobs=-6\n",
    ")\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "f1 = f1_score(y_valid, rfc.predict(X_valid),average='macro')\n",
    "report = classification_report(y_valid, rfc.predict(X_valid))\n",
    "confusion = confusion_matrix(y_valid, rfc.predict(X_valid))\n",
    "\n",
    "print(f1)\n",
    "print(report)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'n_estimators' : [50,100,200],\n",
    "    'criterion' : ['gini','entropy'],\n",
    "    'max_features' : ['auto','sqrt','log2'],\n",
    "    'class_weight' : ['balanced', 'balanced_subsample', None],\n",
    "    'random_state' : [42],\n",
    "    'oob_score' : [True,False]\n",
    "}\n",
    "\n",
    "# params = {\n",
    "#     'class_weight' : ['balanced'], \n",
    "#     'dual' : [False], \n",
    "#     'max_iter' : [500], \n",
    "#     'penalty' : ['l1'], \n",
    "#     'random_state' : [42]\n",
    "# }\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "gsCV = GridSearchCV(\n",
    "    estimator = rfc,\n",
    "    param_grid = params,\n",
    "    scoring = 'f1_macro',\n",
    "    n_jobs = -4,\n",
    "    verbose = 3\n",
    ")\n",
    "\n",
    "gsCV.fit(X_train,y_train)\n",
    "\n",
    "f1 = f1_score(y_valid, gsCV.predict(X_valid),average='macro')\n",
    "report = classification_report(y_valid, gsCV.predict(X_valid))\n",
    "confusion = confusion_matrix(y_valid, gsCV.predict(X_valid))\n",
    "\n",
    "print(f1)\n",
    "print(report)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7738584559325508\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.76      0.74     18800\n",
      "         1.0       0.82      0.79      0.80     25790\n",
      "\n",
      "    accuracy                           0.78     44590\n",
      "   macro avg       0.77      0.78      0.77     44590\n",
      "weighted avg       0.78      0.78      0.78     44590\n",
      "\n",
      "[[14298  4502]\n",
      " [ 5393 20397]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "\n",
    "rfc = LinearSVC(C=10, class_weight='balanced', dual=False, max_iter=100, random_state=42, tol=0.001)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "f1 = f1_score(y_valid, rfc.predict(X_valid),average='macro')\n",
    "report = classification_report(y_valid, rfc.predict(X_valid))\n",
    "confusion = confusion_matrix(y_valid, rfc.predict(X_valid))\n",
    "\n",
    "print(f1)\n",
    "print(report)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 840 candidates, totalling 4200 fits\n",
      "0.7177860909354472\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.71      0.68     18800\n",
      "         1.0       0.78      0.73      0.75     25790\n",
      "\n",
      "    accuracy                           0.72     44590\n",
      "   macro avg       0.72      0.72      0.72     44590\n",
      "weighted avg       0.73      0.72      0.72     44590\n",
      "\n",
      "[[13441  5359]\n",
      " [ 7047 18743]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'penalty' : ['l1','l2'],\n",
    "    'dual' : [False], # [True, False],\n",
    "    'tol' : [1e-3,1e-4,1e-5],\n",
    "    'fit_intercept' : [True, False],\n",
    "    'class_weight' : ['balanced', None],\n",
    "    # 'verbose' : [1],\n",
    "    'max_iter' : [100,200,500,1000,2000],\n",
    "    'random_state' : [42],\n",
    "    'C' : [1,5,10,50,100,500,1000]\n",
    "}\n",
    "\n",
    "# params = {\n",
    "#     'class_weight' : ['balanced'], \n",
    "#     'dual' : [False], \n",
    "#     'max_iter' : [500], \n",
    "#     'penalty' : ['l1'], \n",
    "#     'random_state' : [42]\n",
    "# }\n",
    "\n",
    "rfc = LinearSVC()\n",
    "\n",
    "gsCV = GridSearchCV(\n",
    "    estimator = rfc,\n",
    "    param_grid = params,\n",
    "    scoring = 'f1_macro',\n",
    "    n_jobs = -4,\n",
    "    verbose = 3\n",
    ")\n",
    "\n",
    "gsCV.fit(X_train,y_train)\n",
    "\n",
    "f1 = f1_score(y_valid, gsCV.predict(X_valid),average='macro')\n",
    "report = classification_report(y_valid, gsCV.predict(X_valid))\n",
    "confusion = confusion_matrix(y_valid, gsCV.predict(X_valid))\n",
    "\n",
    "print(f1)\n",
    "print(report)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=10, class_weight='balanced', dual=False, max_iter=100,\n",
       "          random_state=42, tol=0.001)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsCV.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7023192652722203\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.65      0.65     28199\n",
      "           1       0.75      0.76      0.75     38686\n",
      "\n",
      "    accuracy                           0.71     66885\n",
      "   macro avg       0.70      0.70      0.70     66885\n",
      "weighted avg       0.71      0.71      0.71     66885\n",
      "\n",
      "[[18285  9914]\n",
      " [ 9464 29222]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "\n",
    "rfc = GaussianNB()\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "f1 = f1_score(y_valid, rfc.predict(X_valid),average='macro')\n",
    "report = classification_report(y_valid, rfc.predict(X_valid))\n",
    "confusion = confusion_matrix(y_valid, rfc.predict(X_valid))\n",
    "\n",
    "print(f1)\n",
    "print(report)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7335232472069035\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.63      0.68     28199\n",
      "           1       0.75      0.83      0.79     38686\n",
      "\n",
      "    accuracy                           0.75     66885\n",
      "   macro avg       0.74      0.73      0.73     66885\n",
      "weighted avg       0.75      0.75      0.74     66885\n",
      "\n",
      "[[17625 10574]\n",
      " [ 6392 32294]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "\n",
    "rfc = LogisticRegression(n_jobs=-4)\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "f1 = f1_score(y_test, rfc.predict(X_test),average='macro')\n",
    "report = classification_report(y_test, rfc.predict(X_test))\n",
    "confusion = confusion_matrix(y_test, rfc.predict(X_test))\n",
    "\n",
    "print(f1)\n",
    "print(report)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.56999814\n",
      "Iteration 2, loss = 0.54440468\n",
      "Iteration 3, loss = 0.54240847\n",
      "Iteration 4, loss = 0.54047893\n",
      "Iteration 5, loss = 0.53869067\n",
      "Iteration 6, loss = 0.53682975\n",
      "Iteration 7, loss = 0.53520252\n",
      "Iteration 8, loss = 0.53349645\n",
      "Iteration 9, loss = 0.53177883\n",
      "Iteration 10, loss = 0.53044132\n",
      "Iteration 11, loss = 0.52913975\n",
      "Iteration 12, loss = 0.52780389\n",
      "Iteration 13, loss = 0.52658603\n",
      "Iteration 14, loss = 0.52547633\n",
      "Iteration 15, loss = 0.52441353\n",
      "Iteration 16, loss = 0.52312409\n",
      "Iteration 17, loss = 0.52223343\n",
      "Iteration 18, loss = 0.52109321\n",
      "Iteration 19, loss = 0.52009236\n",
      "Iteration 20, loss = 0.51897507\n",
      "Iteration 21, loss = 0.51800636\n",
      "Iteration 22, loss = 0.51728088\n",
      "Iteration 23, loss = 0.51633078\n",
      "Iteration 24, loss = 0.51520809\n",
      "Iteration 25, loss = 0.51445030\n",
      "Iteration 26, loss = 0.51337090\n",
      "Iteration 27, loss = 0.51238160\n",
      "Iteration 28, loss = 0.51141686\n",
      "Iteration 29, loss = 0.51072541\n",
      "Iteration 30, loss = 0.50988250\n",
      "Iteration 31, loss = 0.50899344\n",
      "Iteration 32, loss = 0.50826318\n",
      "Iteration 33, loss = 0.50726533\n",
      "Iteration 34, loss = 0.50649312\n",
      "Iteration 35, loss = 0.50581515\n",
      "Iteration 36, loss = 0.50500407\n",
      "Iteration 37, loss = 0.50396329\n",
      "Iteration 38, loss = 0.50337145\n",
      "Iteration 39, loss = 0.50265093\n",
      "Iteration 40, loss = 0.50173117\n",
      "Iteration 41, loss = 0.50110331\n",
      "Iteration 42, loss = 0.50056807\n",
      "Iteration 43, loss = 0.49948784\n",
      "Iteration 44, loss = 0.49934846\n",
      "Iteration 45, loss = 0.49822473\n",
      "Iteration 46, loss = 0.49775140\n",
      "Iteration 47, loss = 0.49704685\n",
      "Iteration 48, loss = 0.49640872\n",
      "Iteration 49, loss = 0.49572421\n",
      "Iteration 50, loss = 0.49530441\n",
      "Iteration 51, loss = 0.49450472\n",
      "Iteration 52, loss = 0.49386477\n",
      "Iteration 53, loss = 0.49323782\n",
      "Iteration 54, loss = 0.49261984\n",
      "Iteration 55, loss = 0.49214881\n",
      "Iteration 56, loss = 0.49174902\n",
      "Iteration 57, loss = 0.49135601\n",
      "Iteration 58, loss = 0.49069099\n",
      "Iteration 59, loss = 0.49024220\n",
      "Iteration 60, loss = 0.48964359\n",
      "Iteration 61, loss = 0.48927331\n",
      "Iteration 62, loss = 0.48876362\n",
      "Iteration 63, loss = 0.48839561\n",
      "Iteration 64, loss = 0.48792037\n",
      "Iteration 65, loss = 0.48742557\n",
      "Iteration 66, loss = 0.48687435\n",
      "Iteration 67, loss = 0.48621394\n",
      "Iteration 68, loss = 0.48639992\n",
      "Iteration 69, loss = 0.48540499\n",
      "Iteration 70, loss = 0.48512978\n",
      "Iteration 71, loss = 0.48463025\n",
      "Iteration 72, loss = 0.48418264\n",
      "Iteration 73, loss = 0.48418107\n",
      "Iteration 74, loss = 0.48368838\n",
      "Iteration 75, loss = 0.48330779\n",
      "Iteration 76, loss = 0.48297823\n",
      "Iteration 77, loss = 0.48238191\n",
      "Iteration 78, loss = 0.48193929\n",
      "Iteration 79, loss = 0.48163352\n",
      "Iteration 80, loss = 0.48102396\n",
      "Iteration 81, loss = 0.48115805\n",
      "Iteration 82, loss = 0.48074661\n",
      "Iteration 83, loss = 0.48007899\n",
      "Iteration 84, loss = 0.47997423\n",
      "Iteration 85, loss = 0.47947263\n",
      "Iteration 86, loss = 0.47949214\n",
      "Iteration 87, loss = 0.47882485\n",
      "Iteration 88, loss = 0.47839626\n",
      "Iteration 89, loss = 0.47808161\n",
      "Iteration 90, loss = 0.47824514\n",
      "Iteration 91, loss = 0.47746157\n",
      "Iteration 92, loss = 0.47709259\n",
      "Iteration 93, loss = 0.47679371\n",
      "Iteration 94, loss = 0.47687866\n",
      "Iteration 95, loss = 0.47621285\n",
      "Iteration 96, loss = 0.47587529\n",
      "Iteration 97, loss = 0.47578932\n",
      "Iteration 98, loss = 0.47547553\n",
      "Iteration 99, loss = 0.47574092\n",
      "Iteration 100, loss = 0.47479792\n",
      "Iteration 101, loss = 0.47467059\n",
      "Iteration 102, loss = 0.47432237\n",
      "Iteration 103, loss = 0.47391281\n",
      "Iteration 104, loss = 0.47381527\n",
      "Iteration 105, loss = 0.47361481\n",
      "Iteration 106, loss = 0.47362390\n",
      "Iteration 107, loss = 0.47327003\n",
      "Iteration 108, loss = 0.47320742\n",
      "Iteration 109, loss = 0.47240850\n",
      "Iteration 110, loss = 0.47232742\n",
      "Iteration 111, loss = 0.47228565\n",
      "Iteration 112, loss = 0.47187560\n",
      "Iteration 113, loss = 0.47155186\n",
      "Iteration 114, loss = 0.47121665\n",
      "Iteration 115, loss = 0.47099586\n",
      "Iteration 116, loss = 0.47089477\n",
      "Iteration 117, loss = 0.47038668\n",
      "Iteration 118, loss = 0.47035444\n",
      "Iteration 119, loss = 0.47018064\n",
      "Iteration 120, loss = 0.46998908\n",
      "Iteration 121, loss = 0.46973086\n",
      "Iteration 122, loss = 0.46978718\n",
      "Iteration 123, loss = 0.46903292\n",
      "Iteration 124, loss = 0.46947611\n",
      "Iteration 125, loss = 0.46928190\n",
      "Iteration 126, loss = 0.46856363\n",
      "Iteration 127, loss = 0.46856651\n",
      "Iteration 128, loss = 0.46835439\n",
      "Iteration 129, loss = 0.46828559\n",
      "Iteration 130, loss = 0.46838590\n",
      "Iteration 131, loss = 0.46764582\n",
      "Iteration 132, loss = 0.46744351\n",
      "Iteration 133, loss = 0.46726611\n",
      "Iteration 134, loss = 0.46728538\n",
      "Iteration 135, loss = 0.46695136\n",
      "Iteration 136, loss = 0.46689397\n",
      "Iteration 137, loss = 0.46647098\n",
      "Iteration 138, loss = 0.46636817\n",
      "Iteration 139, loss = 0.46621752\n",
      "Iteration 140, loss = 0.46572121\n",
      "Iteration 141, loss = 0.46616133\n",
      "Iteration 142, loss = 0.46560096\n",
      "Iteration 143, loss = 0.46553456\n",
      "Iteration 144, loss = 0.46526015\n",
      "Iteration 145, loss = 0.46514600\n",
      "Iteration 146, loss = 0.46525145\n",
      "Iteration 147, loss = 0.46524189\n",
      "Iteration 148, loss = 0.46451600\n",
      "Iteration 149, loss = 0.46472063\n",
      "Iteration 150, loss = 0.46466727\n",
      "Iteration 151, loss = 0.46396733\n",
      "Iteration 152, loss = 0.46419255\n",
      "Iteration 153, loss = 0.46394523\n",
      "Iteration 154, loss = 0.46388715\n",
      "Iteration 155, loss = 0.46335796\n",
      "Iteration 156, loss = 0.46325564\n",
      "Iteration 157, loss = 0.46320558\n",
      "Iteration 158, loss = 0.46311735\n",
      "Iteration 159, loss = 0.46296980\n",
      "Iteration 160, loss = 0.46329244\n",
      "Iteration 161, loss = 0.46278070\n",
      "Iteration 162, loss = 0.46243918\n",
      "Iteration 163, loss = 0.46245430\n",
      "Iteration 164, loss = 0.46219095\n",
      "Iteration 165, loss = 0.46205871\n",
      "Iteration 166, loss = 0.46198166\n",
      "Iteration 167, loss = 0.46185078\n",
      "Iteration 168, loss = 0.46189362\n",
      "Iteration 169, loss = 0.46150283\n",
      "Iteration 170, loss = 0.46101131\n",
      "Iteration 171, loss = 0.46120805\n",
      "Iteration 172, loss = 0.46126215\n",
      "Iteration 173, loss = 0.46087396\n",
      "Iteration 174, loss = 0.46096510\n",
      "Iteration 175, loss = 0.46046987\n",
      "Iteration 176, loss = 0.46046666\n",
      "Iteration 177, loss = 0.46044936\n",
      "Iteration 178, loss = 0.46056235\n",
      "Iteration 179, loss = 0.46025065\n",
      "Iteration 180, loss = 0.46014711\n",
      "Iteration 181, loss = 0.45987615\n",
      "Iteration 182, loss = 0.45985106\n",
      "Iteration 183, loss = 0.45978112\n",
      "Iteration 184, loss = 0.45944542\n",
      "Iteration 185, loss = 0.45967315\n",
      "Iteration 186, loss = 0.45940383\n",
      "Iteration 187, loss = 0.45914220\n",
      "Iteration 188, loss = 0.45924586\n",
      "Iteration 189, loss = 0.45891563\n",
      "Iteration 190, loss = 0.45919264\n",
      "Iteration 191, loss = 0.45883107\n",
      "Iteration 192, loss = 0.45859420\n",
      "Iteration 193, loss = 0.45898136\n",
      "Iteration 194, loss = 0.45840057\n",
      "Iteration 195, loss = 0.45864569\n",
      "Iteration 196, loss = 0.45803618\n",
      "Iteration 197, loss = 0.45761392\n",
      "Iteration 198, loss = 0.45785852\n",
      "Iteration 199, loss = 0.45787796\n",
      "Iteration 200, loss = 0.45752831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\data_science_lab_2\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6693705135515255\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.52      0.59     28451\n",
      "           1       0.70      0.81      0.75     39048\n",
      "\n",
      "    accuracy                           0.69     67499\n",
      "   macro avg       0.68      0.67      0.67     67499\n",
      "weighted avg       0.69      0.69      0.68     67499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "rfc = MLPClassifier(verbose = True)\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "f1 = f1_score(y_test, rfc.predict(X_test),average='macro')\n",
    "report = classification_report(y_test, rfc.predict(X_test))\n",
    "\n",
    "print(f1)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7041128433588708\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.52      0.62     28199\n",
      "           1       0.71      0.89      0.79     38686\n",
      "\n",
      "    accuracy                           0.73     66885\n",
      "   macro avg       0.74      0.70      0.70     66885\n",
      "weighted avg       0.74      0.73      0.72     66885\n",
      "\n",
      "[[14526 13673]\n",
      " [ 4388 34298]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "\n",
    "rfc = SGDClassifier(n_jobs=-5, random_state=50)\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "f1 = f1_score(y_test, rfc.predict(X_test),average='macro')\n",
    "report = classification_report(y_test, rfc.predict(X_test))\n",
    "confusion = confusion_matrix(y_test, rfc.predict(X_test))\n",
    "\n",
    "print(f1)\n",
    "print(report)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "\n",
    "rfc = SVC(random_state=50)\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "f1 = f1_score(y_test, rfc.predict(X_test),average='macro')\n",
    "report = classification_report(y_test, rfc.predict(X_test))\n",
    "confusion = confusion_matrix(y_test, rfc.predict(X_test))\n",
    "\n",
    "print(f1)\n",
    "print(report)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# rfc = LinearSVC(random_state=70)\n",
    "\n",
    "# rfc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rfc.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_pred.astype(int),columns=['Predicted']).to_csv(\"output2.csv\",index_label=\"Id\", header=[\"Predicted\"])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bd8ee3559d665fee903f84f74f9742602cb00cb47768a52cae0fe6e115d1a823"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('data_science_lab_2': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
